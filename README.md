# Desafio T√©cnico Arko - Plataforma de An√°lise de Dados

![Python](https://img.shields.io/badge/Python-3.11-3776AB?style=for-the-badge&logo=python)
![Django](https://img.shields.io/badge/Django-5.2-092E20?style=for-the-badge&logo=django)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15-336791?style=for-the-badge&logo=postgresql)
![Docker](https://img.shields.io/badge/Docker-20.10-2496ED?style=for-the-badge&logo=docker)
![Pandas](https://img.shields.io/badge/Pandas-2.0-130654?style=for-the-badge&logo=pandas)

## üìñ Descri√ß√£o do Projeto

Esta √© uma aplica√ß√£o web completa desenvolvida com Django, criada como solu√ß√£o para o Desafio T√©cnico da Arko. A aplica√ß√£o consome e processa dados de duas fontes distintas: uma API REST (IBGE) e um ficheiro CSV de grande volume (Receita Federal). Os dados s√£o armazenados numa base de dados PostgreSQL e apresentados numa interface web com funcionalidades de listagem, filtragem e pagina√ß√£o.

O projeto foi totalmente containerizado com Docker para garantir um ambiente de desenvolvimento e execu√ß√£o 100% reprodut√≠vel.

### ‚ú® Nota de Inten√ß√£o e Arquitetura

A arquitetura do projeto foi uma decis√£o deliberada para alinhar a solu√ß√£o diretamente com os requisitos. Optei por usar o padr√£o **MTV (Model-Template-View)** nativo do Django, pois o desafio pedia a cria√ß√£o de "p√°ginas web" renderizadas no servidor. A utiliza√ß√£o do Django Rest Framework (DRF) foi considerada, mas descartada para evitar "over-engineering", uma vez que uma API n√£o era um requisito. A √™nfase foi colocada na robustez do backend, na performance do processamento de dados e na qualidade do c√≥digo atrav√©s de testes unit√°rios.

## üöÄ Funcionalidades

* **Importa√ß√£o de Dados do IBGE:** Um comando otimizado (`importer`) que consome o endpoint de Distritos da API do IBGE para popular de forma eficiente as tabelas de Regi√µes, Estados, Munic√≠pios e Distritos, fazendo apenas uma chamada de rede.
* **Importa√ß√£o de Dados da Receita Federal:** Um comando robusto e autossuficiente (`populate_companies`) que **descarrega automaticamente** o ficheiro ZIP da Receita Federal, processa o CSV de grande volume (+1.7 GB) em `chunks` para efici√™ncia de mem√≥ria e utiliza `bulk operations` do Django para uma inser√ß√£o perform√°tica, atualizando registos existentes sem duplicar.
* **Interface Web Segura:** P√°ginas para listar todas as entidades (Estados, Munic√≠pios, Distritos e Empresas), com funcionalidades completas de **filtragem por campo** e **pagina√ß√£o**.
* **Autentica√ß√£o:** O acesso a todas as p√°ginas de dados √© protegido e requer login de utilizador.
* **Testes Automatizados:** O projeto inclui testes unit√°rios para a l√≥gica de neg√≥cio mais cr√≠tica (o processamento de "chunks" de empresas), garantindo a qualidade e a confiabilidade do c√≥digo.

## üõ†Ô∏è Tecnologias Utilizadas

* **Backend:** Python 3.11, Django
* **Base de Dados:** PostgreSQL
* **Containeriza√ß√£o:** Docker, Docker Compose
* **Bibliotecas Principais:**
    * `pandas`: Para processamento de alta performance do ficheiro CSV.
    * `django-filter`: Para a cria√ß√£o de filtros din√¢micos nas p√°ginas web.
    * `pydantic`: Para a valida√ß√£o robusta dos dados da API.
    * `psycopg2-binary`: Driver de conex√£o com o PostgreSQL.
    * `django-environ`: Para a gest√£o segura de vari√°veis de ambiente.
    * `tqdm`: Para exibir uma barra de progresso durante o download de ficheiros.

## ‚öôÔ∏è Pr√©-requisitos

* [Git](https://git-scm.com/)
* [Docker](https://www.docker.com/products/docker-desktop/)
* [Docker Compose](https://docs.docker.com/compose/install/) (geralmente j√° vem com o Docker Desktop)

## üöÄ Como Executar o Projeto

Siga estes passos para configurar e executar a aplica√ß√£o localmente.

### 1. Clonar o Reposit√≥rio
```bash
git clone https://github.com/guilhermekaua1/desafio-arko
cd desafio-arko
```

### 2. Configura√ß√£o de Vari√°veis de Ambiente
O projeto utiliza um ficheiro `.env` para gerir as configura√ß√µes.

```bash
cp .env.example .env
```
**Importante:** Abra o ficheiro `.env` e gere uma nova `SECRET_KEY` para o Django. Pode usar o comando abaixo (com Python instalado na sua m√°quina) para gerar uma:
```bash
python3 -c 'from django.core.management.utils import get_random_secret_key; print(get_random_secret_key())'
```
Cole a chave gerada no seu ficheiro `.env`.

### 3. Construir e Iniciar os Containers
Este comando ir√° construir a imagem da aplica√ß√£o Django e iniciar os servi√ßos da web e da base de dados.
```bash
docker-compose up --build -d
```

### 4. Configurar a Base de Dados
Com os contentores em execu√ß√£o, aplique as migra√ß√µes para criar todas as tabelas na base de dados.
```bash
docker-compose exec web python manage.py migrate
```

### 5. Acessar √† Aplica√ß√£o
Para poder fazer login, crie primeiro um superutilizador:
```bash
docker-compose exec web python manage.py createsuperuser
```
Siga as instru√ß√µes para definir um nome de utilizador, e-mail e senha.

### 6. Executar as Rotinas de Importa√ß√£o de Dados

Para uma base de dados completa, recomenda-se executar os tr√™s comandos abaixo.

**a. Importador Otimizado do IBGE (R√°pido):**
Este comando utiliza uma estrat√©gia otimizada, fazendo uma √∫nica chamada ao endpoint de `distritos` da API do IBGE para popular a maioria das entidades.

```bash
docker-compose exec web python manage.py importer
```

**b. Importador Completo do IBGE (Garantia de Integridade):**
Este comando busca os dados de cada entidade (Estados, Munic√≠pios) em endpoints separados. √â mais lento, mas serve como rotina complementar para garantir que mesmo os munic√≠pios que n√£o tenham distritos registados na API sejam importados.
```bash
docker-compose exec web python manage.py populate_ibge
```

**c. Importador de Empresas (Receita Federal via S3):**
Este comando descarrega e processa o ficheiro de dados de empresas.
*Nota: Para garantir uma importa√ß√£o r√°pida e est√°vel para a avalia√ß√£o, o ficheiro ZIP original da Receita Federal (~400MB) foi previamente alojado num bucket Amazon S3 de alta velocidade. O comando abaixo utiliza esta fonte otimizada.*
**O download dever√° ser quase instant√¢neo, mas o processamento das mais de 22 milh√µes de linhas ainda pode levar de 10 a 30 minutos.**
```bash
docker-compose exec web python manage.py populate_companies [https://desafio-arko-empresas-final.s3.us-east-1.amazonaws.com/Empresas0.zip](https://desafio-arko-empresas-final.s3.us-east-1.amazonaws.com/Empresas0.zip)
```

### 6. Como Testar o Projeto
O projeto inclui testes unit√°rios para a l√≥gica de importa√ß√£o de empresas. Para os executar:
```bash
docker-compose exec web python manage.py test data_importer
```

## ‚ö° Execu√ß√£o Alternativa (sem Docker)

Para executar o projeto localmente sem Docker, ser√° necess√°rio ter o Python 3.11+ e o PostgreSQL instalados na sua m√°quina.

1.  **Crie e ative um ambiente virtual:**
    ```bash
    python3 -m venv .venv
    source venv/bin/activate  # Linux/macOS
    venv\Scripts\activate      # Windows
    ```
2.  **Instale as depend√™ncias:**
    ```bash
    pip install -r requirements.txt
    ```
3.  **Configure as vari√°veis de ambiente:** Crie um ficheiro `.env` (a partir do `.env.example`) e ajuste as vari√°veis da base de dados (`DB_HOST`, `DB_PORT`, etc.) para corresponderem √† sua instala√ß√£o local do PostgreSQL.
4.  **Execute as migra√ß√µes e os comandos de importa√ß√£o:**
    ```bash
    python manage.py migrate
    python manage.py importer
    python manage.py populate_companies https://desafio-arko-empresas-final.s3.us-east-1.amazonaws.com/Empresas0.zip
    ```
5.  **Inicie o servidor:**
    ```bash
    python manage.py runserver
    ```

### 7. Acessar √† Aplica√ß√£o

**a. Acessar √†s P√°ginas Web (Tarefa 3):**
* Aceda a **http://localhost:8000/**
* Fa√ßa login com as credenciais que acabou de criar.
* Voc√™ ser√° redirecionado para a lista de estados e poder√° navegar por todas as p√°ginas da aplica√ß√£o.

**b. Acessar ao Django Admin:**
* Aceda a **http://localhost:8000/admin/**
* Use as mesmas credenciais para ver a √°rea de gest√£o de dados.

## üîå Acessar √† Base de Dados Diretamente

A base de dados do PostgreSQL dentro do contentor est√° exposta na porta `5432` da sua m√°quina local (`localhost`). Pode usar uma ferramenta como DBeaver, Postico ou pgAdmin para se conectar a ela com as seguintes credenciais (do ficheiro `.env`):
* **Host:** `localhost`
* **Porta:** `5432`
* **Utilizador:** `arko_user` (ou o que estiver no seu `.env`)
* **Senha:** `supersecretpassword` (ou o que estiver no seu `.env`)
* **Base de Dados:** `arko_db` (ou o que estiver no seu `.env`)